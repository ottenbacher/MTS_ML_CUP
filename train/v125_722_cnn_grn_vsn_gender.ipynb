{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c01e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix, vstack, load_npz\n",
    "\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sys import getsizeof\n",
    "import gc\n",
    "#from catboost import CatBoostRegressor, cv, Pool, sum_models\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "import vaex\n",
    "import pyarrow.parquet as pq\n",
    "import bisect\n",
    "\n",
    "import pickle\n",
    "from random import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ProgbarLogger\n",
    "from tensorflow.keras import regularizers as R\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import optimizers as O\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, categorical_crossentropy\n",
    "#from tensorflow.keras import mixed_precision\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "tf.random.set_seed(722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ad6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = 'context_data'\n",
    "SPLIT_SEED = 42\n",
    "DATA_FILE = 'competition_data_final_pqt'\n",
    "TARGET_FILE = 'public_train.pqt'\n",
    "SUBMISSION_FILE = 'submit_2.pqt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e20da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_submit = pq.read_table(f'../{LOCAL_DATA_PATH}/{SUBMISSION_FILE}').to_pandas()\n",
    "tgt = pq.read_table(f'../{LOCAL_DATA_PATH}/{TARGET_FILE}').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028dd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = load_npz('../utils/mat.npz').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35b87e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264326, 87555) (144724, 87555)\n"
     ]
    }
   ],
   "source": [
    "idx_tr = tgt['is_male'][(tgt.is_male == '0') | (tgt.is_male == '1')].index.values\n",
    "y_train = tgt['is_male'][(tgt.is_male == '0') | (tgt.is_male == '1')].values.astype(np.int8)\n",
    "\n",
    "mat_train = mat[idx_tr]\n",
    "idx_test = id_to_submit.user_id.values\n",
    "mat_test = mat[idx_test]\n",
    "\n",
    "cols_countsum_tr = np.asarray(mat_train.astype(bool).sum(axis=0)).flatten()\n",
    "cols_countsum_test = np.asarray(mat_test.astype(bool).sum(axis=0)).flatten()\n",
    "mask = (cols_countsum_tr > 1) * (cols_countsum_test > 0)\n",
    "\n",
    "mat_train = mat_train[:, mask]\n",
    "mat_test = mat_test[:, mask]\n",
    "print(mat_train.shape, mat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a26fd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>morning</th>\n",
       "      <th>night</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>...</th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "      <th>os</th>\n",
       "      <th>region_name_count</th>\n",
       "      <th>city_name_count</th>\n",
       "      <th>req_max</th>\n",
       "      <th>req_sum</th>\n",
       "      <th>id_rows</th>\n",
       "      <th>days</th>\n",
       "      <th>dates_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.554404</td>\n",
       "      <td>0.321244</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.134715</td>\n",
       "      <td>0.108808</td>\n",
       "      <td>0.036269</td>\n",
       "      <td>0.440415</td>\n",
       "      <td>...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Galaxy J1 2016 LTE Dual</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>131</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.346705</td>\n",
       "      <td>0.295129</td>\n",
       "      <td>0.322827</td>\n",
       "      <td>0.035339</td>\n",
       "      <td>0.127985</td>\n",
       "      <td>0.209169</td>\n",
       "      <td>0.102197</td>\n",
       "      <td>0.098376</td>\n",
       "      <td>0.122254</td>\n",
       "      <td>0.150907</td>\n",
       "      <td>...</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>Mi 9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1047</td>\n",
       "      <td>700</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.316302</td>\n",
       "      <td>0.187348</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.128954</td>\n",
       "      <td>0.148418</td>\n",
       "      <td>0.150852</td>\n",
       "      <td>0.104623</td>\n",
       "      <td>0.128954</td>\n",
       "      <td>...</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>Honor 9 Lite</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>411</td>\n",
       "      <td>356</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.178182</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.185455</td>\n",
       "      <td>0.065455</td>\n",
       "      <td>0.116364</td>\n",
       "      <td>0.123636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>Huawei Device Company Limited</td>\n",
       "      <td>P Smart 2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>275</td>\n",
       "      <td>188</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348777</td>\n",
       "      <td>0.265122</td>\n",
       "      <td>0.371943</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0.212355</td>\n",
       "      <td>0.164736</td>\n",
       "      <td>0.185328</td>\n",
       "      <td>0.141570</td>\n",
       "      <td>0.118404</td>\n",
       "      <td>0.072072</td>\n",
       "      <td>...</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>Nova 3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>777</td>\n",
       "      <td>591</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              day   evening   morning     night    Friday    Monday  Saturday  \\\n",
       "user_id                                                                         \n",
       "0        0.554404  0.321244  0.119171  0.005181  0.056995  0.020725  0.134715   \n",
       "1        0.346705  0.295129  0.322827  0.035339  0.127985  0.209169  0.102197   \n",
       "2        0.481752  0.316302  0.187348  0.014599  0.153285  0.128954  0.148418   \n",
       "3        0.352727  0.454545  0.178182  0.014545  0.240000  0.185455  0.065455   \n",
       "4        0.348777  0.265122  0.371943  0.014157  0.212355  0.164736  0.185328   \n",
       "\n",
       "           Sunday  Thursday   Tuesday  ...                        company  \\\n",
       "user_id                                ...                                  \n",
       "0        0.108808  0.036269  0.440415  ...                        Samsung   \n",
       "1        0.098376  0.122254  0.150907  ...                         Xiaomi   \n",
       "2        0.150852  0.104623  0.128954  ...                         Huawei   \n",
       "3        0.116364  0.123636  0.090909  ...  Huawei Device Company Limited   \n",
       "4        0.141570  0.118404  0.072072  ...                         Huawei   \n",
       "\n",
       "                           model os region_name_count city_name_count req_max  \\\n",
       "user_id                                                                         \n",
       "0        Galaxy J1 2016 LTE Dual  1                 1               1       5   \n",
       "1                           Mi 9  1                 3               6       6   \n",
       "2                   Honor 9 Lite  1                 1               1       4   \n",
       "3                   P Smart 2021  1                 1               1       5   \n",
       "4                         Nova 3  1                 5               9       5   \n",
       "\n",
       "         req_sum  id_rows  days  dates_range  \n",
       "user_id                                       \n",
       "0            193      131    17           18  \n",
       "1           1047      700    19           20  \n",
       "2            411      356    50           57  \n",
       "3            275      188    15           16  \n",
       "4            777      591    20           42  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_df = pd.read_csv('../utils/feat_gen_df3.csv', index_col='user_id')\n",
    "feat_df['os'] = feat_df['os'].map({'iOS': 0, 'Android': 1})\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "959d7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feat = feat_df.drop(['region_name', 'city_name', 'company', 'model'], axis=1).values\n",
    "cont_feat_train = cont_feat[idx_tr]\n",
    "cont_feat_test = cont_feat[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5f5274",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = feat_df[['region_name', 'city_name', 'company', 'model']]\n",
    "cat_feat = np.stack([cat_df[col].astype('category').cat.codes.values for col in cat_df]).T\n",
    "cat_feat_train = cat_feat[idx_tr]\n",
    "cat_feat_test = cat_feat[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "805eaa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264326, 172344) (144724, 172344)\n"
     ]
    }
   ],
   "source": [
    "mat_pod = load_npz('../utils/mat_pod.npz').astype('float32')\n",
    "mat_pod_train = mat_pod[idx_tr]\n",
    "mat_pod_test = mat_pod[idx_test]\n",
    "\n",
    "mat_pod_cols_countsum_tr = np.asarray(mat_pod_train.astype(bool).sum(axis=0)).flatten()\n",
    "mat_pod_cols_countsum_test = np.asarray(mat_pod_test.astype(bool).sum(axis=0)).flatten()\n",
    "mat_pod_mask = (mat_pod_cols_countsum_tr > 1) * (mat_pod_cols_countsum_test > 0)\n",
    "\n",
    "mat_pod_train = mat_pod_train[:, mat_pod_mask]\n",
    "mat_pod_test = mat_pod_test[:, mat_pod_mask]\n",
    "print(mat_pod_train.shape, mat_pod_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b9b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x1_vals, x2_vals, x3_vals, x4_vals, y_vals, batch_size, split_idx, shuffle_idx=False):\n",
    "        self.x1_vals = x1_vals\n",
    "        self.x2_vals = x2_vals\n",
    "        self.x3_vals = x3_vals\n",
    "        self.x4_vals = x4_vals\n",
    "        self.y_vals = y_vals\n",
    "        self.inds = split_idx\n",
    "        self.shuffle_idx = shuffle_idx\n",
    "        if shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        from_ind = self.batch_size * item\n",
    "        to_ind = self.batch_size * (item + 1)\n",
    "        batch_x1 = self.x1_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        batch_x2 = self.x2_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x3 = self.x3_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x4 = self.x4_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        batch_y = self.y_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        return ([batch_x1, batch_x2, batch_x3, batch_x4], batch_y)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.inds) / float(self.batch_size)))\n",
    "    \n",
    "    \n",
    "class DataGenerator_test(Sequence):\n",
    "    def __init__(self, x1_vals, x2_vals, x3_vals, x4_vals, batch_size, split_idx, shuffle_idx=False):\n",
    "        self.x1_vals = x1_vals\n",
    "        self.x2_vals = x2_vals\n",
    "        self.x3_vals = x3_vals\n",
    "        self.x4_vals = x4_vals\n",
    "        self.inds = split_idx\n",
    "        self.shuffle_idx = shuffle_idx\n",
    "        if shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        from_ind = self.batch_size * item\n",
    "        to_ind = self.batch_size * (item + 1)\n",
    "        batch_x1 = self.x1_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        batch_x2 = self.x2_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x3 = self.x3_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x4 = self.x4_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        return ([batch_x1, batch_x2, batch_x3, batch_x4],)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.inds) / float(self.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f8c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedLinearUnit(L.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.linear = L.Dense(units)\n",
    "        self.sigmoid = L.Dense(units, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.linear(inputs) * self.sigmoid(inputs)\n",
    "    \n",
    "    \n",
    "class GatedResidualNetwork(L.Layer):\n",
    "    def __init__(self, units, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.relu_dense = L.Dense(units, activation=\"relu\")\n",
    "        self.linear_dense = L.Dense(units)\n",
    "        self.dropout = L.Dropout(dropout_rate)\n",
    "        self.gated_linear_unit = GatedLinearUnit(units)\n",
    "        self.layer_norm = L.LayerNormalization()\n",
    "        self.project = L.Dense(units)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.relu_dense(inputs)\n",
    "        x = self.linear_dense(x)\n",
    "        x = self.dropout(x)\n",
    "        if inputs.shape[-1] != self.units:\n",
    "            inputs = self.project(inputs)\n",
    "        x = inputs + self.gated_linear_unit(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class VariableSelection(L.Layer):\n",
    "    def __init__(self, num_features, units, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.grns = list()\n",
    "        # Create a GRN for each feature independently\n",
    "        for idx in range(num_features):\n",
    "            grn = GatedResidualNetwork(units, dropout_rate)\n",
    "            self.grns.append(grn)\n",
    "        # Create a GRN for the concatenation of all the features\n",
    "        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n",
    "        self.softmax = L.Dense(units=num_features, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        v = L.concatenate(inputs)\n",
    "        v = self.grn_concat(v)\n",
    "        v = tf.expand_dims(self.softmax(v), axis=-1)\n",
    "\n",
    "        x = []\n",
    "        for idx, input_ in enumerate(inputs):\n",
    "            x.append(self.grns[idx](input_))\n",
    "        x = tf.stack(x, axis=1)\n",
    "\n",
    "        outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class VariableSelectionFlow(L.Layer):\n",
    "    def __init__(self, num_features, units, dropout_rate, dense_units=None):\n",
    "        super().__init__()\n",
    "        self.variableselection = VariableSelection(num_features, units, dropout_rate)\n",
    "        self.split = L.Lambda(lambda t: tf.split(t, num_features, axis=-1))\n",
    "        self.dense = dense_units\n",
    "        if dense_units:\n",
    "            self.dense_list = [L.Dense(dense_units, \\\n",
    "                                       activation='linear') \\\n",
    "                               for _ in tf.range(num_features)\n",
    "                              ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        split_input = self.split(inputs)\n",
    "        if self.dense:\n",
    "            #@tf.function\n",
    "            #def calc_cycle(layers_list, values_list):\n",
    "            #    return [layers_list[i](values_list[i]) for i in range(len(layers_list))]\n",
    "            #l = calc_cycle(self.dense_list, split_input)\n",
    "            l = [self.dense_list[i](split_input[i]) for i in range(len(self.dense_list))]\n",
    "        else:\n",
    "            l = split_input\n",
    "        return self.variableselection(l)        \n",
    "    \n",
    "    \n",
    "def smish(x):\n",
    "    return x * K.tanh(K.log(1 + K.sigmoid(x)))\n",
    "\n",
    "\n",
    "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
    "\n",
    "    mlp_layers = []\n",
    "    for units in hidden_units:\n",
    "        mlp_layers.append(L.Dense(units, activation=activation))\n",
    "        mlp_layers.append(normalization_layer),\n",
    "        mlp_layers.append(L.Dropout(dropout_rate))\n",
    "\n",
    "    return tf.keras.Sequential(mlp_layers, name=name)\n",
    "\n",
    "\n",
    "class TransformerBlock(L.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.15, num_transformer_blocks=3):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.num_transformer_blocks = num_transformer_blocks\n",
    "        self.att = L.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)\n",
    "        self.ffn = create_mlp(\n",
    "            hidden_units=ff_dim,\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=tf.keras.activations.gelu,\n",
    "            normalization_layer=L.LayerNormalization(epsilon=1e-6),\n",
    "        )\n",
    "        self.layernorm1 = L.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = L.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        for block_idx in range(num_transformer_blocks):\n",
    "            attn_output = self.att(inputs, inputs)\n",
    "            out1 = self.layernorm1(inputs + attn_output)\n",
    "            ffn_output = self.ffn(out1)\n",
    "            inputs = self.layernorm2(out1 + ffn_output)\n",
    "        return inputs\n",
    "\n",
    "    \n",
    "class Wt_Add(L.Layer):\n",
    "    def __init__(self, units=1, input_dim=1):\n",
    "        super(Wt_Add, self).__init__()\n",
    "        w_init = tf.random_normal_initializer(mean=1.0)\n",
    "        self.w1 = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.w2 = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )        \n",
    "        \n",
    "    def call(self, input1, input2):\n",
    "        return tf.multiply(input1,self.w1) + tf.multiply(input2, self.w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e05b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "units_1 = 256\n",
    "units_2 = 64\n",
    "units_22 = 128\n",
    "dropout_1 = 0.1\n",
    "dropout_2 = 0.1\n",
    "dropout_22 = 0.1\n",
    "\n",
    "\n",
    "INIT_LR = 1e-5\n",
    "MAX_LR = 1e-3\n",
    "steps_per_epoch = 930\n",
    "\n",
    "\n",
    "dropout_rate = 0.10\n",
    "num_transformer_blocks = 3  # Number of transformer blocks.\n",
    "num_heads = 4  # Number of attention heads.\n",
    "embedding_dims = 32  # Embedding dimensions of the categorical features.\n",
    "vocab_len = [80, 950, 37, 599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b16742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fbf306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###__--__###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7087419a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 1______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 2450s 2s/step - loss: 0.4965 - auc: 0.8362 - val_loss: 0.4559 - val_auc: 0.8705\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2012s 2s/step - loss: 0.4202 - auc: 0.8883 - val_loss: 0.4241 - val_auc: 0.8865\n",
      "566/566 [==============================] - 454s 703ms/step\n",
      "______fold 2______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 2503s 2s/step - loss: 0.4972 - auc: 0.8357 - val_loss: 0.4648 - val_auc: 0.8678\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2028s 2s/step - loss: 0.4185 - auc: 0.8890 - val_loss: 0.4280 - val_auc: 0.8846\n",
      "566/566 [==============================] - 469s 710ms/step\n",
      "______fold 3______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 2554s 2s/step - loss: 0.4995 - auc: 0.8335 - val_loss: 0.4468 - val_auc: 0.8727\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2060s 2s/step - loss: 0.4209 - auc: 0.8877 - val_loss: 0.4217 - val_auc: 0.8877\n",
      "566/566 [==============================] - 469s 723ms/step\n",
      "______fold 4______\n",
      "Epoch 1/2\n",
      "596/930 [==================>...........] - ETA: 12:05 - loss: 0.5243 - auc: 0.8133"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_10192\\2780788322.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(87555,))\\n    r1_1 = L.Reshape((87555,1))(inputs_1)\\n    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((43758,))(d_1)\\n    features_1 = VariableSelectionFlow(187, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(172344,))\\n    r1_4 = L.Reshape((172344,1))(inputs_4)\\n    cnn_4 = L.Conv1D(4, 64, strides=2, activation=smish)(r1_4)\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86141,))(d_4)\\n    features_4 = VariableSelectionFlow(191, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    outputs = L.Dense(units=1, activation=\"sigmoid\")(features_22)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-9)\\n    loss = binary_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[\\'AUC\\']\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[\\'is_male\\'] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df[\\'is_male\\'].to_csv(f\\'v125_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 92, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11202048,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2726424]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:92\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_10192\\2780788322.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(87555,))\\n    r1_1 = L.Reshape((87555,1))(inputs_1)\\n    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((43758,))(d_1)\\n    features_1 = VariableSelectionFlow(187, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(172344,))\\n    r1_4 = L.Reshape((172344,1))(inputs_4)\\n    cnn_4 = L.Conv1D(4, 64, strides=2, activation=smish)(r1_4)\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86141,))(d_4)\\n    features_4 = VariableSelectionFlow(191, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    outputs = L.Dense(units=1, activation=\"sigmoid\")(features_22)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-9)\\n    loss = binary_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[\\'AUC\\']\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[\\'is_male\\'] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df[\\'is_male\\'].to_csv(f\\'v125_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 92, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11202048,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2726424]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    inputs_1 = tf.keras.Input(shape=(87555,))\n",
    "    r1_1 = L.Reshape((87555,1))(inputs_1)\n",
    "    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((43758,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(187, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(172344,))\n",
    "    r1_4 = L.Reshape((172344,1))(inputs_4)\n",
    "    cnn_4 = L.Conv1D(4, 64, strides=2, activation=smish)(r1_4)\n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86141,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(191, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    outputs = L.Dense(units=1, activation=\"sigmoid\")(features_22)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-9)\n",
    "    loss = binary_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=['AUC']\n",
    "                 )\n",
    "    \n",
    "    history = model.fit(train_gen,\n",
    "                            epochs=2,\n",
    "                            validation_data=val_gen\n",
    "                        )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df['is_male'] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df['is_male'].to_csv(f'v125_722/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea1b2a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 4______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 3134s 3s/step - loss: 0.4980 - auc: 0.8350 - val_loss: 0.4524 - val_auc: 0.8732\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2175s 2s/step - loss: 0.4212 - auc: 0.8876 - val_loss: 0.4229 - val_auc: 0.8874\n",
      "566/566 [==============================] - 559s 835ms/step\n",
      "______fold 5______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 3193s 3s/step - loss: 0.4980 - auc: 0.8349 - val_loss: 0.4733 - val_auc: 0.8645\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2440s 3s/step - loss: 0.4182 - auc: 0.8893 - val_loss: 0.4316 - val_auc: 0.8828\n",
      "566/566 [==============================] - 584s 866ms/step\n",
      "______fold 6______\n",
      "Epoch 1/2\n",
      "400/930 [===========>..................] - ETA: 23:01 - loss: 0.5454 - auc: 0.7932"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_11784\\1320182824.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n  if n>2:  \\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(87555,))\\n    r1_1 = L.Reshape((87555,1))(inputs_1)\\n    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((43758,))(d_1)\\n    features_1 = VariableSelectionFlow(187, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(172344,))\\n    r1_4 = L.Reshape((172344,1))(inputs_4)\\n    cnn_4 = L.Conv1D(4, 64, strides=2, activation=smish)(r1_4)\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86141,))(d_4)\\n    features_4 = VariableSelectionFlow(191, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    outputs = L.Dense(units=1, activation=\"sigmoid\")(features_22)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-9)\\n    loss = binary_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[\\'AUC\\']\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[\\'is_male\\'] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df[\\'is_male\\'].to_csv(f\\'v125_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 93, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11202048,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2009726]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:93\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_11784\\1320182824.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n  if n>2:  \\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(87555,))\\n    r1_1 = L.Reshape((87555,1))(inputs_1)\\n    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((43758,))(d_1)\\n    features_1 = VariableSelectionFlow(187, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(172344,))\\n    r1_4 = L.Reshape((172344,1))(inputs_4)\\n    cnn_4 = L.Conv1D(4, 64, strides=2, activation=smish)(r1_4)\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86141,))(d_4)\\n    features_4 = VariableSelectionFlow(191, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    outputs = L.Dense(units=1, activation=\"sigmoid\")(features_22)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-9)\\n    loss = binary_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[\\'AUC\\']\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[\\'is_male\\'] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df[\\'is_male\\'].to_csv(f\\'v125_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 93, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11202048,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2009726]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "  if n>2:  \n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    inputs_1 = tf.keras.Input(shape=(87555,))\n",
    "    r1_1 = L.Reshape((87555,1))(inputs_1)\n",
    "    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((43758,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(187, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(172344,))\n",
    "    r1_4 = L.Reshape((172344,1))(inputs_4)\n",
    "    cnn_4 = L.Conv1D(4, 64, strides=2, activation=smish)(r1_4)\n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86141,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(191, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    outputs = L.Dense(units=1, activation=\"sigmoid\")(features_22)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-9)\n",
    "    loss = binary_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=['AUC']\n",
    "                 )\n",
    "    \n",
    "    history = model.fit(train_gen,\n",
    "                            epochs=2,\n",
    "                            validation_data=val_gen\n",
    "                        )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df['is_male'] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df['is_male'].to_csv(f'v125_722/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15a899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 6______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 3197s 3s/step - loss: 0.4991 - auc: 0.8344 - val_loss: 0.4515 - val_auc: 0.8713\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2357s 3s/step - loss: 0.4195 - auc: 0.8886 - val_loss: 0.4295 - val_auc: 0.8836\n",
      "566/566 [==============================] - 555s 831ms/step\n",
      "______fold 7______\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:73\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\base_layer.py:944\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 944\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    948\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\base_layer.py:2315\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   2310\u001b[0m     training_arg_passed_by_framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[0;32m   2313\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[0;32m   2314\u001b[0m   \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 2315\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2316\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2318\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2320\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2321\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\base_layer.py:2186\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m   2184\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m   2185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\base_layer.py:2232\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m   2230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m   2231\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m-> 2232\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2234\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m   2235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[0;32m   2236\u001b[0m                         build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileo08k02mv.py:30\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariableselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filequ5vju48.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m v \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(L)\u001b[38;5;241m.\u001b[39mconcatenate, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 11\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrn_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m v \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax, (ag__\u001b[38;5;241m.\u001b[39mld(v),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file8284fyk_.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu_dense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mlinear_dense, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdropout, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\layers\\core\\dense.py:221\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39membedding_lookup_sparse(\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, ids, weights, combiner\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    220\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 221\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtensordot(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, [[rank \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3713\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3710\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops\u001b[38;5;241m.\u001b[39mbatch_mat_mul_v3(\n\u001b[0;32m   3711\u001b[0m       a, b, adj_x\u001b[38;5;241m=\u001b[39madjoint_a, adj_y\u001b[38;5;241m=\u001b[39madjoint_b, Tout\u001b[38;5;241m=\u001b[39moutput_type, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   3712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3713\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmat_mul\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3714\u001b[0m \u001b[43m      \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6033\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6031\u001b[0m   transpose_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   6032\u001b[0m transpose_b \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_bool(transpose_b, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose_b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 6033\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6034\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMatMul\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6035\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6036\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[0;32m   6037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:694\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    692\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    693\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3754\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3751\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3752\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3753\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3754\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3755\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3756\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3757\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3758\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3759\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3760\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3761\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3763\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2129\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2127\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m op_def \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2128\u001b[0m     op_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_get_op_def(node_def\u001b[38;5;241m.\u001b[39mop)\n\u001b[1;32m-> 2129\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2130\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2131\u001b[0m   name \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traceback \u001b[38;5;241m=\u001b[39m tf_stack\u001b[38;5;241m.\u001b[39mextract_stack_for_node(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1933\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1931\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _reconstruct_sequence_inputs(op_def, inputs, node_def\u001b[38;5;241m.\u001b[39mattr)\n\u001b[0;32m   1932\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1933\u001b[0m op_desc \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_NewOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1934\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1935\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_def\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[0;32m   1937\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "  if n>4:  \n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    inputs_1 = tf.keras.Input(shape=(87555,))\n",
    "    r1_1 = L.Reshape((87555,1))(inputs_1)\n",
    "    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((43758,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(187, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(172344,))\n",
    "    r1_4 = L.Reshape((172344,1))(inputs_4)\n",
    "    cnn_4 = L.Conv1D(4, 64, strides=2, activation=smish)(r1_4)\n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86141,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(191, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    outputs = L.Dense(units=1, activation=\"sigmoid\")(features_22)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-9)\n",
    "    loss = binary_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=['AUC']\n",
    "                 )\n",
    "    \n",
    "    history = model.fit(train_gen,\n",
    "                            epochs=2,\n",
    "                            validation_data=val_gen\n",
    "                        )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df['is_male'] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df['is_male'].to_csv(f'v125_722/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cbc8760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 7______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 3042s 3s/step - loss: 0.4991 - auc: 0.8342 - val_loss: 0.4533 - val_auc: 0.8688\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2363s 3s/step - loss: 0.4211 - auc: 0.8877 - val_loss: 0.4272 - val_auc: 0.8851\n",
      "566/566 [==============================] - 552s 833ms/step\n",
      "______fold 8______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 3072s 3s/step - loss: 0.5007 - auc: 0.8330 - val_loss: 0.4610 - val_auc: 0.8722\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2405s 3s/step - loss: 0.4209 - auc: 0.8877 - val_loss: 0.4234 - val_auc: 0.8869\n",
      "566/566 [==============================] - 590s 851ms/step\n",
      "______fold 9______\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "  if n>5:  \n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    inputs_1 = tf.keras.Input(shape=(87555,))\n",
    "    r1_1 = L.Reshape((87555,1))(inputs_1)\n",
    "    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((43758,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(187, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(172344,))\n",
    "    r1_4 = L.Reshape((172344,1))(inputs_4)\n",
    "    cnn_4 = L.Conv1D(4, 64, strides=2, activation=smish)(r1_4)\n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86141,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(191, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    outputs = L.Dense(units=1, activation=\"sigmoid\")(features_22)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-9)\n",
    "    loss = binary_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=['AUC']\n",
    "                 )\n",
    "    \n",
    "    history = model.fit(train_gen,\n",
    "                            epochs=2,\n",
    "                            validation_data=val_gen\n",
    "                        )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df['is_male'] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df['is_male'].to_csv(f'v125_722/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76958c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 9______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 3088s 3s/step - loss: 0.4981 - auc: 0.8350 - val_loss: 0.4570 - val_auc: 0.8679\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2372s 3s/step - loss: 0.4208 - auc: 0.8879 - val_loss: 0.4255 - val_auc: 0.8851\n",
      "566/566 [==============================] - 550s 828ms/step\n",
      "______fold 10______\n",
      "Epoch 1/2\n",
      "930/930 [==============================] - 3069s 3s/step - loss: 0.4976 - auc: 0.8352 - val_loss: 0.4526 - val_auc: 0.8707\n",
      "Epoch 2/2\n",
      "930/930 [==============================] - 2429s 3s/step - loss: 0.4191 - auc: 0.8887 - val_loss: 0.4295 - val_auc: 0.8839\n",
      "566/566 [==============================] - 572s 841ms/step\n",
      "CPU times: total: 2h 29min 19s\n",
      "Wall time: 3h 23min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "  if n>7:  \n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    inputs_1 = tf.keras.Input(shape=(87555,))\n",
    "    r1_1 = L.Reshape((87555,1))(inputs_1)\n",
    "    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((43758,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(187, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(172344,))\n",
    "    r1_4 = L.Reshape((172344,1))(inputs_4)\n",
    "    cnn_4 = L.Conv1D(4, 64, strides=2, activation=smish)(r1_4)\n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86141,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(191, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    outputs = L.Dense(units=1, activation=\"sigmoid\")(features_22)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-9)\n",
    "    loss = binary_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=['AUC']\n",
    "                 )\n",
    "    \n",
    "    history = model.fit(train_gen,\n",
    "                            epochs=2,\n",
    "                            validation_data=val_gen\n",
    "                        )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df['is_male'] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df['is_male'].to_csv(f'v125_722/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07a4b73d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 87555)]      0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 172344)]     0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 87555, 1)     0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 172344, 1)    0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              [(None, 1),          0           ['input_3[0][0]']                \n",
      "                                 (None, 1),                                                       \n",
      "                                 (None, 1),                                                       \n",
      "                                 (None, 1)]                                                       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 43758, 16)    672         ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 86141, 4)     260         ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 32)        2560        ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 32)        30400       ['lambda_2[0][1]']               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 1, 32)        1184        ['lambda_2[0][2]']               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 1, 32)        19168       ['lambda_2[0][3]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 43758, 1)     17          ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1069 (Dense)             (None, 86141, 1)     5           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 4, 32)        0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]',            \n",
      "                                                                  'embedding_2[0][0]',            \n",
      "                                                                  'embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 43758)        0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 86141)        0           ['dense_1069[0][0]']             \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " transformer_block (Transformer  (None, 4, 32)       18048       ['tf.concat[0][0]']              \n",
      " Block)                                                                                           \n",
      "                                                                                                  \n",
      " variable_selection_flow (Varia  (None, 256)         82155451    ['reshape_1[0][0]']              \n",
      " bleSelectionFlow)                                                                                \n",
      "                                                                                                  \n",
      " variable_selection_flow_2 (Var  (None, 256)         126350271   ['reshape_3[0][0]']              \n",
      " iableSelectionFlow)                                                                              \n",
      "                                                                                                  \n",
      " variable_selection_flow_1 (Var  (None, 64)          273916      ['input_2[0][0]']                \n",
      " iableSelectionFlow)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['transformer_block[0][0]']      \n",
      "                                                                                                  \n",
      " wt__add (Wt_Add)               (None, 256)          512         ['variable_selection_flow[0][0]',\n",
      "                                                                  'variable_selection_flow_2[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 448)          0           ['variable_selection_flow_1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'wt__add[0][0]']                \n",
      "                                                                                                  \n",
      " variable_selection_flow_3 (Var  (None, 128)         22758720    ['concatenate[0][0]']            \n",
      " iableSelectionFlow)                                                                              \n",
      "                                                                                                  \n",
      " dense_4277 (Dense)             (None, 1)            129         ['variable_selection_flow_3[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 231,611,313\n",
      "Trainable params: 231,611,313\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7de82f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device(\"/CPU:0\"):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b2652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_env_v1] *",
   "language": "python",
   "name": "conda-env-ml_env_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
