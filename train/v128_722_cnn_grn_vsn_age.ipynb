{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c01e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix, vstack, load_npz\n",
    "\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sys import getsizeof\n",
    "import gc\n",
    "#from catboost import CatBoostRegressor, cv, Pool, sum_models\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "import vaex\n",
    "import pyarrow.parquet as pq\n",
    "import bisect\n",
    "\n",
    "import pickle\n",
    "from random import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ProgbarLogger\n",
    "from tensorflow.keras import regularizers as R\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import optimizers as O\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "tf.random.set_seed(722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ad6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = 'context_data'\n",
    "SPLIT_SEED = 42\n",
    "DATA_FILE = 'competition_data_final_pqt'\n",
    "TARGET_FILE = 'public_train.pqt'\n",
    "SUBMISSION_FILE = 'submit_2.pqt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e20da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_submit = pq.read_table(f'../{LOCAL_DATA_PATH}/{SUBMISSION_FILE}').to_pandas()\n",
    "tgt = pq.read_table(f'../{LOCAL_DATA_PATH}/{TARGET_FILE}').to_pandas()\n",
    "\n",
    "def age_bucket(x):\n",
    "    return bisect.bisect_left([18,25,35,45,55,65], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028dd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = load_npz('../utils/mat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35b87e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269903, 88072) (144724, 88072)\n"
     ]
    }
   ],
   "source": [
    "idx_tr = tgt['age'][tgt.age > 15].index.values\n",
    "y_train = tgt['age'][tgt.age > 15].map(age_bucket).values.astype(np.int8)\n",
    "y_train[y_train==0] = 1\n",
    "y_train = y_train - 1\n",
    "\n",
    "mat_train = mat[idx_tr]\n",
    "idx_test = id_to_submit.user_id.values\n",
    "mat_test = mat[idx_test]\n",
    "\n",
    "cols_countsum_tr = np.asarray(mat_train.astype(bool).sum(axis=0)).flatten()\n",
    "cols_countsum_test = np.asarray(mat_test.astype(bool).sum(axis=0)).flatten()\n",
    "mask = (cols_countsum_tr > 1) * (cols_countsum_test > 0)\n",
    "\n",
    "mat_train = mat_train[:, mask]\n",
    "mat_test = mat_test[:, mask]\n",
    "print(mat_train.shape, mat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a26fd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>morning</th>\n",
       "      <th>night</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>...</th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "      <th>os</th>\n",
       "      <th>region_name_count</th>\n",
       "      <th>city_name_count</th>\n",
       "      <th>req_max</th>\n",
       "      <th>req_sum</th>\n",
       "      <th>id_rows</th>\n",
       "      <th>days</th>\n",
       "      <th>dates_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.554404</td>\n",
       "      <td>0.321244</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.134715</td>\n",
       "      <td>0.108808</td>\n",
       "      <td>0.036269</td>\n",
       "      <td>0.440415</td>\n",
       "      <td>...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Galaxy J1 2016 LTE Dual</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>131</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.346705</td>\n",
       "      <td>0.295129</td>\n",
       "      <td>0.322827</td>\n",
       "      <td>0.035339</td>\n",
       "      <td>0.127985</td>\n",
       "      <td>0.209169</td>\n",
       "      <td>0.102197</td>\n",
       "      <td>0.098376</td>\n",
       "      <td>0.122254</td>\n",
       "      <td>0.150907</td>\n",
       "      <td>...</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>Mi 9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1047</td>\n",
       "      <td>700</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.316302</td>\n",
       "      <td>0.187348</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.128954</td>\n",
       "      <td>0.148418</td>\n",
       "      <td>0.150852</td>\n",
       "      <td>0.104623</td>\n",
       "      <td>0.128954</td>\n",
       "      <td>...</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>Honor 9 Lite</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>411</td>\n",
       "      <td>356</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.178182</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.185455</td>\n",
       "      <td>0.065455</td>\n",
       "      <td>0.116364</td>\n",
       "      <td>0.123636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>Huawei Device Company Limited</td>\n",
       "      <td>P Smart 2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>275</td>\n",
       "      <td>188</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348777</td>\n",
       "      <td>0.265122</td>\n",
       "      <td>0.371943</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0.212355</td>\n",
       "      <td>0.164736</td>\n",
       "      <td>0.185328</td>\n",
       "      <td>0.141570</td>\n",
       "      <td>0.118404</td>\n",
       "      <td>0.072072</td>\n",
       "      <td>...</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>Nova 3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>777</td>\n",
       "      <td>591</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              day   evening   morning     night    Friday    Monday  Saturday  \\\n",
       "user_id                                                                         \n",
       "0        0.554404  0.321244  0.119171  0.005181  0.056995  0.020725  0.134715   \n",
       "1        0.346705  0.295129  0.322827  0.035339  0.127985  0.209169  0.102197   \n",
       "2        0.481752  0.316302  0.187348  0.014599  0.153285  0.128954  0.148418   \n",
       "3        0.352727  0.454545  0.178182  0.014545  0.240000  0.185455  0.065455   \n",
       "4        0.348777  0.265122  0.371943  0.014157  0.212355  0.164736  0.185328   \n",
       "\n",
       "           Sunday  Thursday   Tuesday  ...                        company  \\\n",
       "user_id                                ...                                  \n",
       "0        0.108808  0.036269  0.440415  ...                        Samsung   \n",
       "1        0.098376  0.122254  0.150907  ...                         Xiaomi   \n",
       "2        0.150852  0.104623  0.128954  ...                         Huawei   \n",
       "3        0.116364  0.123636  0.090909  ...  Huawei Device Company Limited   \n",
       "4        0.141570  0.118404  0.072072  ...                         Huawei   \n",
       "\n",
       "                           model os region_name_count city_name_count req_max  \\\n",
       "user_id                                                                         \n",
       "0        Galaxy J1 2016 LTE Dual  1                 1               1       5   \n",
       "1                           Mi 9  1                 3               6       6   \n",
       "2                   Honor 9 Lite  1                 1               1       4   \n",
       "3                   P Smart 2021  1                 1               1       5   \n",
       "4                         Nova 3  1                 5               9       5   \n",
       "\n",
       "         req_sum  id_rows  days  dates_range  \n",
       "user_id                                       \n",
       "0            193      131    17           18  \n",
       "1           1047      700    19           20  \n",
       "2            411      356    50           57  \n",
       "3            275      188    15           16  \n",
       "4            777      591    20           42  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_df = pd.read_csv('../utils/feat_gen_df3.csv', index_col='user_id')\n",
    "feat_df['os'] = feat_df['os'].map({'iOS': 0, 'Android': 1})\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "959d7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feat = feat_df.drop(['region_name', 'city_name', 'company', 'model'], axis=1).values\n",
    "cont_feat_train = cont_feat[idx_tr]\n",
    "cont_feat_test = cont_feat[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5f5274",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = feat_df[['region_name', 'city_name', 'company', 'model']]\n",
    "cat_feat = np.stack([cat_df[col].astype('category').cat.codes.values for col in cat_df]).T\n",
    "cat_feat_train = cat_feat[idx_tr]\n",
    "cat_feat_test = cat_feat[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "805eaa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269903, 173452) (144724, 173452)\n"
     ]
    }
   ],
   "source": [
    "mat_pod = load_npz('../utils/mat_pod.npz')\n",
    "mat_pod_train = mat_pod[idx_tr]\n",
    "mat_pod_test = mat_pod[idx_test]\n",
    "\n",
    "mat_pod_cols_countsum_tr = np.asarray(mat_pod_train.astype(bool).sum(axis=0)).flatten()\n",
    "mat_pod_cols_countsum_test = np.asarray(mat_pod_test.astype(bool).sum(axis=0)).flatten()\n",
    "mat_pod_mask = (mat_pod_cols_countsum_tr > 1) * (mat_pod_cols_countsum_test > 0)\n",
    "\n",
    "mat_pod_train = mat_pod_train[:, mat_pod_mask]\n",
    "mat_pod_test = mat_pod_test[:, mat_pod_mask]\n",
    "print(mat_pod_train.shape, mat_pod_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b9b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x1_vals, x2_vals, x3_vals, x4_vals, y_vals, batch_size, split_idx, shuffle_idx=False):\n",
    "        self.x1_vals = x1_vals\n",
    "        self.x2_vals = x2_vals\n",
    "        self.x3_vals = x3_vals\n",
    "        self.x4_vals = x4_vals\n",
    "        self.y_vals = y_vals\n",
    "        self.inds = split_idx\n",
    "        self.shuffle_idx = shuffle_idx\n",
    "        if shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        from_ind = self.batch_size * item\n",
    "        to_ind = self.batch_size * (item + 1)\n",
    "        batch_x1 = self.x1_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        batch_x2 = self.x2_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x3 = self.x3_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x4 = self.x4_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        batch_y = self.y_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        return ([batch_x1, batch_x2, batch_x3, batch_x4], tf.one_hot(batch_y, depth=6))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.inds) / float(self.batch_size)))\n",
    "    \n",
    "    \n",
    "class DataGenerator_test(Sequence):\n",
    "    def __init__(self, x1_vals, x2_vals, x3_vals, x4_vals, batch_size, split_idx, shuffle_idx=False):\n",
    "        self.x1_vals = x1_vals\n",
    "        self.x2_vals = x2_vals\n",
    "        self.x3_vals = x3_vals\n",
    "        self.x4_vals = x4_vals\n",
    "        self.inds = split_idx\n",
    "        self.shuffle_idx = shuffle_idx\n",
    "        if shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        from_ind = self.batch_size * item\n",
    "        to_ind = self.batch_size * (item + 1)\n",
    "        batch_x1 = self.x1_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        batch_x2 = self.x2_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x3 = self.x3_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x4 = self.x4_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        return ([batch_x1, batch_x2, batch_x3, batch_x4],)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.inds) / float(self.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f8c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedLinearUnit(L.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.linear = L.Dense(units)\n",
    "        self.sigmoid = L.Dense(units, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.linear(inputs) * self.sigmoid(inputs)\n",
    "    \n",
    "    \n",
    "class GatedResidualNetwork(L.Layer):\n",
    "    def __init__(self, units, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.relu_dense = L.Dense(units, activation=\"relu\")\n",
    "        self.linear_dense = L.Dense(units)\n",
    "        self.dropout = L.Dropout(dropout_rate)\n",
    "        self.gated_linear_unit = GatedLinearUnit(units)\n",
    "        self.layer_norm = L.LayerNormalization()\n",
    "        self.project = L.Dense(units)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.relu_dense(inputs)\n",
    "        x = self.linear_dense(x)\n",
    "        x = self.dropout(x)\n",
    "        if inputs.shape[-1] != self.units:\n",
    "            inputs = self.project(inputs)\n",
    "        x = inputs + self.gated_linear_unit(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class VariableSelection(L.Layer):\n",
    "    def __init__(self, num_features, units, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.grns = list()\n",
    "        # Create a GRN for each feature independently\n",
    "        for idx in range(num_features):\n",
    "            grn = GatedResidualNetwork(units, dropout_rate)\n",
    "            self.grns.append(grn)\n",
    "        # Create a GRN for the concatenation of all the features\n",
    "        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n",
    "        self.softmax = L.Dense(units=num_features, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        v = L.concatenate(inputs)\n",
    "        v = self.grn_concat(v)\n",
    "        v = tf.expand_dims(self.softmax(v), axis=-1)\n",
    "\n",
    "        x = []\n",
    "        for idx, input_ in enumerate(inputs):\n",
    "            x.append(self.grns[idx](input_))\n",
    "        x = tf.stack(x, axis=1)\n",
    "\n",
    "        outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class VariableSelectionFlow(L.Layer):\n",
    "    def __init__(self, num_features, units, dropout_rate, dense_units=None):\n",
    "        super().__init__()\n",
    "        self.variableselection = VariableSelection(num_features, units, dropout_rate)\n",
    "        self.split = L.Lambda(lambda t: tf.split(t, num_features, axis=-1))\n",
    "        self.dense = dense_units\n",
    "        if dense_units:\n",
    "            self.dense_list = [L.Dense(dense_units, \\\n",
    "                                       activation='linear') \\\n",
    "                               for _ in tf.range(num_features)\n",
    "                              ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        split_input = self.split(inputs)\n",
    "        if self.dense:\n",
    "            #@tf.function\n",
    "            #def calc_cycle(layers_list, values_list):\n",
    "            #    return [layers_list[i](values_list[i]) for i in range(len(layers_list))]\n",
    "            #l = calc_cycle(self.dense_list, split_input)\n",
    "            l = [self.dense_list[i](split_input[i]) for i in range(len(self.dense_list))]\n",
    "        else:\n",
    "            l = split_input\n",
    "        return self.variableselection(l)        \n",
    "    \n",
    "    \n",
    "def smish(x):\n",
    "    return x * K.tanh(K.log(1 + K.sigmoid(x)))\n",
    "\n",
    "\n",
    "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
    "\n",
    "    mlp_layers = []\n",
    "    for units in hidden_units:\n",
    "        mlp_layers.append(L.Dense(units, activation=activation))\n",
    "        mlp_layers.append(normalization_layer),\n",
    "        mlp_layers.append(L.Dropout(dropout_rate))\n",
    "\n",
    "    return tf.keras.Sequential(mlp_layers, name=name)\n",
    "\n",
    "\n",
    "class TransformerBlock(L.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.15, num_transformer_blocks=3):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.num_transformer_blocks = num_transformer_blocks\n",
    "        self.att = L.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)\n",
    "        self.ffn = create_mlp(\n",
    "            hidden_units=ff_dim,\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=tf.keras.activations.gelu,\n",
    "            normalization_layer=L.LayerNormalization(epsilon=1e-6),\n",
    "        )\n",
    "        self.layernorm1 = L.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = L.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        for block_idx in range(num_transformer_blocks):\n",
    "            attn_output = self.att(inputs, inputs)\n",
    "            out1 = self.layernorm1(inputs + attn_output)\n",
    "            ffn_output = self.ffn(out1)\n",
    "            inputs = self.layernorm2(out1 + ffn_output)\n",
    "        return inputs\n",
    "\n",
    "    \n",
    "class Wt_Add(L.Layer):\n",
    "    def __init__(self, units=1, input_dim=1):\n",
    "        super(Wt_Add, self).__init__()\n",
    "        w_init = tf.random_normal_initializer(mean=1.0)\n",
    "        self.w1 = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.w2 = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )        \n",
    "        \n",
    "    def call(self, input1, input2):\n",
    "        return tf.multiply(input1,self.w1) + tf.multiply(input2, self.w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e05b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "units_1 = 256\n",
    "units_2 = 64\n",
    "units_22 = 128\n",
    "dropout_1 = 0.1\n",
    "dropout_2 = 0.1\n",
    "dropout_22 = 0.1\n",
    "\n",
    "\n",
    "INIT_LR = 1e-5\n",
    "MAX_LR = 1e-3\n",
    "steps_per_epoch = 949\n",
    "\n",
    "\n",
    "dropout_rate = 0.10\n",
    "num_transformer_blocks = 3  # Number of transformer blocks.\n",
    "num_heads = 4  # Number of attention heads.\n",
    "embedding_dims = 32  # Embedding dimensions of the categorical features.\n",
    "vocab_len = [80, 950, 37, 599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b16742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fbf306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###__--__###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7087419a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 1______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 3314s 3s/step - loss: 1.3054 - f1_score: 0.4214 - val_loss: 1.2450 - val_f1_score: 0.4470\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2514s 3s/step - loss: 1.1818 - f1_score: 0.4870 - val_loss: 1.1914 - val_f1_score: 0.4861\n",
      "566/566 [==============================] - 570s 868ms/step\n",
      "______fold 2______\n",
      "Epoch 1/2\n",
      " 61/949 [>.............................] - ETA: 39:00 - loss: 1.6104 - f1_score: 0.2665"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_13320\\1978120453.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(88072,))\\n    r1_1 = L.Reshape((88072,1))(inputs_1)\\n    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((44016,))(d_1)\\n    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(173452,))\\n    r1_4 = L.Reshape((173452,1))(inputs_4)\\n    cnn_4 = L.Conv1D(4, 53, strides=2, activation=smish)(r1_4)\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86700,))(d_4)\\n    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    dense_out = L.Dense(6)(features_22)\\n    outputs = L.Activation(\"softmax\", dtype=\\'float32\\')(dense_out)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\\n    loss = categorical_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[F1Score(num_classes=6, average=\\'weighted\\')]\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df.to_csv(f\\'v128_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 93, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11268096,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1370040]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:93\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_13320\\1978120453.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(88072,))\\n    r1_1 = L.Reshape((88072,1))(inputs_1)\\n    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((44016,))(d_1)\\n    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(173452,))\\n    r1_4 = L.Reshape((173452,1))(inputs_4)\\n    cnn_4 = L.Conv1D(4, 53, strides=2, activation=smish)(r1_4)\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86700,))(d_4)\\n    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    dense_out = L.Dense(6)(features_22)\\n    outputs = L.Activation(\"softmax\", dtype=\\'float32\\')(dense_out)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\\n    loss = categorical_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[F1Score(num_classes=6, average=\\'weighted\\')]\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df.to_csv(f\\'v128_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 93, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11268096,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1370040]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    inputs_1 = tf.keras.Input(shape=(88072,))\n",
    "    r1_1 = L.Reshape((88072,1))(inputs_1)\n",
    "    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((44016,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(173452,))\n",
    "    r1_4 = L.Reshape((173452,1))(inputs_4)\n",
    "    cnn_4 = L.Conv1D(4, 53, strides=2, activation=smish)(r1_4)\n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86700,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    dense_out = L.Dense(6)(features_22)\n",
    "    outputs = L.Activation(\"softmax\", dtype='float32')(dense_out)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\n",
    "    loss = categorical_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=[F1Score(num_classes=6, average='weighted')]\n",
    "                 )\n",
    "    \n",
    "    history = model.fit(train_gen,\n",
    "                            epochs=2,\n",
    "                            validation_data=val_gen\n",
    "                        )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df.to_csv(f'v128_722/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8047b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 2______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 3268s 3s/step - loss: 1.3042 - f1_score: 0.4238 - val_loss: 1.2338 - val_f1_score: 0.4509\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2502s 3s/step - loss: 1.1818 - f1_score: 0.4883 - val_loss: 1.1900 - val_f1_score: 0.4861\n",
      "566/566 [==============================] - 579s 866ms/step\n",
      "______fold 3______\n",
      "Epoch 1/2\n",
      "114/949 [==>...........................] - ETA: 36:26 - loss: 1.5142 - f1_score: 0.3075"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_6336\\2141415696.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n  if n>0:\\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(88072,))\\n    r1_1 = L.Reshape((88072,1))(inputs_1)\\n    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((44016,))(d_1)\\n    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(173452,))\\n    r1_4 = L.Reshape((173452,1))(inputs_4)\\n    cnn_4 = L.Conv1D(4, 53, strides=2, activation=smish)(r1_4)\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86700,))(d_4)\\n    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    dense_out = L.Dense(6)(features_22)\\n    outputs = L.Activation(\"softmax\", dtype=\\'float32\\')(dense_out)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\\n    loss = categorical_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[F1Score(num_classes=6, average=\\'weighted\\')]\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df.to_csv(f\\'v128_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 94, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11268096,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1370040]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:94\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_6336\\2141415696.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n  if n>0:\\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(88072,))\\n    r1_1 = L.Reshape((88072,1))(inputs_1)\\n    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((44016,))(d_1)\\n    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(173452,))\\n    r1_4 = L.Reshape((173452,1))(inputs_4)\\n    cnn_4 = L.Conv1D(4, 53, strides=2, activation=smish)(r1_4)\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86700,))(d_4)\\n    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    dense_out = L.Dense(6)(features_22)\\n    outputs = L.Activation(\"softmax\", dtype=\\'float32\\')(dense_out)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\\n    loss = categorical_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[F1Score(num_classes=6, average=\\'weighted\\')]\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df.to_csv(f\\'v128_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 94, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11268096,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1370040]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "  if n>0:\n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    inputs_1 = tf.keras.Input(shape=(88072,))\n",
    "    r1_1 = L.Reshape((88072,1))(inputs_1)\n",
    "    cnn_1 = L.Conv1D(16, 41, strides=2, activation=smish)(r1_1)\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((44016,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(173452,))\n",
    "    r1_4 = L.Reshape((173452,1))(inputs_4)\n",
    "    cnn_4 = L.Conv1D(4, 53, strides=2, activation=smish)(r1_4)\n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86700,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    dense_out = L.Dense(6)(features_22)\n",
    "    outputs = L.Activation(\"softmax\", dtype='float32')(dense_out)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\n",
    "    loss = categorical_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=[F1Score(num_classes=6, average='weighted')]\n",
    "                 )\n",
    "    \n",
    "    history = model.fit(train_gen,\n",
    "                            epochs=2,\n",
    "                            validation_data=val_gen\n",
    "                        )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df.to_csv(f'v128_722/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a542919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 3______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 3278s 3s/step - loss: 1.2980 - f1_score: 0.4273 - val_loss: 1.2213 - val_f1_score: 0.4629\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2488s 3s/step - loss: 1.1761 - f1_score: 0.4899 - val_loss: 1.1918 - val_f1_score: 0.4858\n",
      "566/566 [==============================] - 575s 847ms/step\n",
      "______fold 4______\n",
      "Epoch 1/2\n",
      "594/949 [=================>............] - ETA: 15:20 - loss: 1.3299 - f1_score: 0.4081"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_10300\\819355953.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n  if n>1:\\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(88072,), dtype=tf.uint16)\\n    r1_1 = L.Reshape((1,88072,1))(inputs_1)\\n    cnn_1 = L.Conv2D(16, (1,41), strides=2, activation=smish)(tf.cast(r1_1, tf.float32))\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((44016,))(d_1)\\n    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(173452,), dtype=tf.uint16)\\n    r1_4 = L.Reshape((1,173452,1))(inputs_4)\\n    cnn_4 = L.Conv2D(4, (1,53), strides=2, activation=smish)(tf.cast(r1_4, tf.float32))\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86700,))(d_4)\\n    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    dense_out = L.Dense(6)(features_22)\\n    outputs = L.Activation(\"softmax\", dtype=\\'float32\\')(dense_out)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\\n    loss = categorical_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[F1Score(num_classes=6, average=\\'weighted\\')]\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df.to_csv(f\\'v128_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 94, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11268096,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1400542]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:94\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/dense/Tensordot/MatMul/MatMul' defined at (most recent call last):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Room722\\AppData\\Local\\Temp\\ipykernel_10300\\819355953.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', '\\n\\ntest_gen = DataGenerator_test(mat_test,\\\\\\n                              cont_feat_test,\\\\\\n                              cat_feat_test,\\\\\\n                              mat_pod_test,\\\\\\n                              batch_size,\\n                              np.arange(mat_test.shape[0])\\n                           )\\n\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\\nfor n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\\n  if n>1:\\n    print(f\\'______fold {n+1}______\\')\\n    train_idx = np.sort(train_idx)\\n    val_idx = np.sort(val_idx) \\n    train_gen = DataGenerator(mat_train,\\\\\\n                              cont_feat_train,\\\\\\n                              cat_feat_train,\\\\\\n                              mat_pod_train,\\\\\\n                              y_train,\\\\\\n                              batch_size,\\\\\\n                              train_idx,\\\\\\n                              shuffle_idx=True\\n                             )\\n    val_gen = DataGenerator(mat_train,\\\\\\n                            cont_feat_train,\\\\\\n                            cat_feat_train,\\\\\\n                            mat_pod_train,\\\\\\n                            y_train,\\\\\\n                            batch_size,\\n                            val_idx\\n                           )\\n    \\n    inputs_1 = tf.keras.Input(shape=(88072,), dtype=tf.uint16)\\n    r1_1 = L.Reshape((1,88072,1))(inputs_1)\\n    cnn_1 = L.Conv2D(16, (1,41), strides=2, activation=smish)(tf.cast(r1_1, tf.float32))\\n    d_1 = L.Dense(1, activation=smish)(cnn_1)\\n    r2_1 = L.Reshape((44016,))(d_1)\\n    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\\n    \\n   \\n    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\\n    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\\n\\n    \\n    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\\n    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\\n    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\\n    cat_emb = tf.concat(emb, axis=1)    \\n    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\\\\n                                 num_heads=num_heads, \\\\\\n                                 ff_dim=[embedding_dims], \\\\\\n                                 dropout_rate=dropout_rate, \\\\\\n                                 num_transformer_blocks=num_transformer_blocks\\n                                )(cat_emb)\\n\\n    # Flatten the \"contextualized\" embeddings of the categorical features.\\n    cat_features = L.Flatten()(transf_cat)\\n    \\n    \\n    inputs_4 = tf.keras.Input(shape=(173452,), dtype=tf.uint16)\\n    r1_4 = L.Reshape((1,173452,1))(inputs_4)\\n    cnn_4 = L.Conv2D(4, (1,53), strides=2, activation=smish)(tf.cast(r1_4, tf.float32))\\n    d_4 = L.Dense(1, activation=smish)(cnn_4)    \\n    r2_4 = L.Reshape((86700,))(d_4)\\n    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \\n\\n    \\n    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\\n    \\n    \\n    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\\n    \\n    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\\n    \\n    dense_out = L.Dense(6)(features_22)\\n    outputs = L.Activation(\"softmax\", dtype=\\'float32\\')(dense_out)\\n\\n    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\\n                \\n    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\\n        maximal_learning_rate=MAX_LR,\\n        scale_fn=lambda x: 1/(2.**(x-1)),\\n        step_size=1 * steps_per_epoch\\n        )\\n    \\n    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\\n    loss = categorical_crossentropy\\n\\n    model.compile(optimizer=opt, \\n                    loss=loss,\\n                    metrics=[F1Score(num_classes=6, average=\\'weighted\\')]\\n                 )\\n    \\n    history = model.fit(train_gen,\\n                            epochs=2,\\n                            validation_data=val_gen\\n                        )\\n\\n    y_test_df = pd.DataFrame(idx_test).rename({0: \\'user_id\\'}, axis=1)\\n    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\\n    y_test_df = y_test_df.set_index(\\'user_id\\', drop=True)\\n    y_test_df.to_csv(f\\'v128_722/fold_{n+1}/y_test.csv\\')\\n    \\n    K.clear_session()\\n')\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2357, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 94, in <module>\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense/Tensordot/MatMul/MatMul'\nOOM when allocating tensor with shape[11268096,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense/Tensordot/MatMul/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1400542]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "  if n>1:\n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    inputs_1 = tf.keras.Input(shape=(88072,), dtype=tf.uint16)\n",
    "    r1_1 = L.Reshape((1,88072,1))(inputs_1)\n",
    "    cnn_1 = L.Conv2D(16, (1,41), strides=2, activation=smish)(tf.cast(r1_1, tf.float32))\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((44016,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(173452,), dtype=tf.uint16)\n",
    "    r1_4 = L.Reshape((1,173452,1))(inputs_4)\n",
    "    cnn_4 = L.Conv2D(4, (1,53), strides=2, activation=smish)(tf.cast(r1_4, tf.float32))\n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86700,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    dense_out = L.Dense(6)(features_22)\n",
    "    outputs = L.Activation(\"softmax\", dtype='float32')(dense_out)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\n",
    "    loss = categorical_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=[F1Score(num_classes=6, average='weighted')]\n",
    "                 )\n",
    "    \n",
    "    history = model.fit(train_gen,\n",
    "                            epochs=2,\n",
    "                            validation_data=val_gen\n",
    "                        )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df.to_csv(f'v128_722/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ed2695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3080 Laptop GPU, compute capability 8.6\n",
      "______fold 4______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2726s 2s/step - loss: 1.3028 - f1_score: 0.4238 - val_loss: 1.2406 - val_f1_score: 0.4622\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2212s 2s/step - loss: 1.1787 - f1_score: 0.4893 - val_loss: 1.1973 - val_f1_score: 0.4794\n",
      "566/566 [==============================] - 493s 768ms/step\n",
      "______fold 5______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2799s 2s/step - loss: 1.3100 - f1_score: 0.4201 - val_loss: 1.2337 - val_f1_score: 0.4630\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2256s 2s/step - loss: 1.1832 - f1_score: 0.4864 - val_loss: 1.1899 - val_f1_score: 0.4849\n",
      "566/566 [==============================] - 510s 789ms/step\n",
      "______fold 6______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2799s 2s/step - loss: 1.2989 - f1_score: 0.4252 - val_loss: 1.2363 - val_f1_score: 0.4522\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2248s 2s/step - loss: 1.1828 - f1_score: 0.4854 - val_loss: 1.1792 - val_f1_score: 0.4887\n",
      "566/566 [==============================] - 501s 773ms/step\n",
      "______fold 7______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2771s 2s/step - loss: 1.3045 - f1_score: 0.4224 - val_loss: 1.2217 - val_f1_score: 0.4605\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2239s 2s/step - loss: 1.1832 - f1_score: 0.4872 - val_loss: 1.1810 - val_f1_score: 0.4836\n",
      "566/566 [==============================] - 510s 788ms/step\n",
      "______fold 8______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2791s 2s/step - loss: 1.3003 - f1_score: 0.4235 - val_loss: 1.2335 - val_f1_score: 0.4536\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2255s 2s/step - loss: 1.1809 - f1_score: 0.4880 - val_loss: 1.1912 - val_f1_score: 0.4815\n",
      "566/566 [==============================] - 512s 791ms/step\n",
      "______fold 9______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2736s 2s/step - loss: 1.3056 - f1_score: 0.4214 - val_loss: 1.2348 - val_f1_score: 0.4561\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2244s 2s/step - loss: 1.1864 - f1_score: 0.4834 - val_loss: 1.1962 - val_f1_score: 0.4845\n",
      "566/566 [==============================] - 498s 767ms/step\n",
      "______fold 10______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2803s 2s/step - loss: 1.3050 - f1_score: 0.4225 - val_loss: 1.2458 - val_f1_score: 0.4376\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2264s 2s/step - loss: 1.1751 - f1_score: 0.4905 - val_loss: 1.1879 - val_f1_score: 0.4840\n",
      "566/566 [==============================] - 521s 807ms/step\n",
      "CPU times: total: 5h 13min 24s\n",
      "Wall time: 10h 50min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "policy_m16 = mixed_precision.Policy('mixed_float16')\n",
    "policy_32 = mixed_precision.Policy('float32')\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "  if n>2:\n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    mixed_precision.set_global_policy(policy_m16)\n",
    "\n",
    "    inputs_1 = tf.keras.Input(shape=(88072,))\n",
    "    r1_1 = L.Reshape((1,88072,1))(inputs_1)\n",
    "    cnn_1 = L.Conv2D(16, (1,41), strides=2, activation=smish)(r1_1)\n",
    "    \n",
    "    mixed_precision.set_global_policy(policy_32)\n",
    "\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((44016,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "\n",
    "    mixed_precision.set_global_policy(policy_m16)    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(173452,))\n",
    "    r1_4 = L.Reshape((1,173452,1))(inputs_4)\n",
    "    cnn_4 = L.Conv2D(4, (1,53), strides=2, activation=smish)(r1_4)\n",
    "    \n",
    "    mixed_precision.set_global_policy(policy_32)\n",
    "    \n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86700,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    dense_out = L.Dense(6)(features_22)\n",
    "    outputs = L.Activation(\"softmax\", dtype='float32')(dense_out)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\n",
    "    loss = categorical_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=[F1Score(num_classes=6, average='weighted')]\n",
    "                 )\n",
    "    \n",
    "    model.fit(train_gen,\n",
    "                epochs=2,\n",
    "                validation_data=val_gen\n",
    "            )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df.to_csv(f'v128_722/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    del model, clr, opt, loss\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cedecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07a4b73d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 88072)]      0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 173452)]     0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 88072, 1)     0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 173452, 1)    0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              [(None, 1),          0           ['input_3[0][0]']                \n",
      "                                 (None, 1),                                                       \n",
      "                                 (None, 1),                                                       \n",
      "                                 (None, 1)]                                                       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 44016, 16)    672         ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 86700, 4)     216         ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 32)        2560        ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 32)        30400       ['lambda_2[0][1]']               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 1, 32)        1184        ['lambda_2[0][2]']               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 1, 32)        19168       ['lambda_2[0][3]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 44016, 1)     17          ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_974 (Dense)              (None, 86700, 1)     5           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 4, 32)        0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]',            \n",
      "                                                                  'embedding_2[0][0]',            \n",
      "                                                                  'embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 44016)        0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 86700)        0           ['dense_974[0][0]']              \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " transformer_block (Transformer  (None, 4, 32)       18048       ['tf.concat[0][0]']              \n",
      " Block)                                                                                           \n",
      "                                                                                                  \n",
      " variable_selection_flow (Varia  (None, 256)         78645160    ['reshape_1[0][0]']              \n",
      " bleSelectionFlow)                                                                                \n",
      "                                                                                                  \n",
      " variable_selection_flow_2 (Var  (None, 256)         139636735   ['reshape_3[0][0]']              \n",
      " iableSelectionFlow)                                                                              \n",
      "                                                                                                  \n",
      " variable_selection_flow_1 (Var  (None, 64)          273916      ['input_2[0][0]']                \n",
      " iableSelectionFlow)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['transformer_block[0][0]']      \n",
      "                                                                                                  \n",
      " wt__add (Wt_Add)               (None, 256)          512         ['variable_selection_flow[0][0]',\n",
      "                                                                  'variable_selection_flow_2[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 448)          0           ['variable_selection_flow_1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'wt__add[0][0]']                \n",
      "                                                                                                  \n",
      " variable_selection_flow_3 (Var  (None, 128)         22758720    ['concatenate[0][0]']            \n",
      " iableSelectionFlow)                                                                              \n",
      "                                                                                                  \n",
      " dense_4502 (Dense)             (None, 6)            774         ['variable_selection_flow_3[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 6)            0           ['dense_4502[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 241,388,087\n",
      "Trainable params: 241,388,087\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9241c910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_env_v1] *",
   "language": "python",
   "name": "conda-env-ml_env_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
