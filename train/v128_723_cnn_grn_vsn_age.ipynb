{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c01e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Miniconda3\\envs\\ml_env_v1\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix, vstack, load_npz\n",
    "\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sys import getsizeof\n",
    "import gc\n",
    "#from catboost import CatBoostRegressor, cv, Pool, sum_models\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "import vaex\n",
    "import pyarrow.parquet as pq\n",
    "import bisect\n",
    "\n",
    "import pickle\n",
    "from random import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ProgbarLogger\n",
    "from tensorflow.keras import regularizers as R\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import optimizers as O\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "tf.random.set_seed(722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ad6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = 'context_data'\n",
    "SPLIT_SEED = 42\n",
    "DATA_FILE = 'competition_data_final_pqt'\n",
    "TARGET_FILE = 'public_train.pqt'\n",
    "SUBMISSION_FILE = 'submit_2.pqt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e20da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_submit = pq.read_table(f'../{LOCAL_DATA_PATH}/{SUBMISSION_FILE}').to_pandas()\n",
    "tgt = pq.read_table(f'../{LOCAL_DATA_PATH}/{TARGET_FILE}').to_pandas()\n",
    "\n",
    "def age_bucket(x):\n",
    "    return bisect.bisect_left([18,25,35,45,55,65], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028dd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = load_npz('../utils/mat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35b87e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269903, 88072) (144724, 88072)\n"
     ]
    }
   ],
   "source": [
    "idx_tr = tgt['age'][tgt.age > 15].index.values\n",
    "y_train = tgt['age'][tgt.age > 15].map(age_bucket).values.astype(np.int8)\n",
    "y_train[y_train==0] = 1\n",
    "y_train = y_train - 1\n",
    "\n",
    "mat_train = mat[idx_tr]\n",
    "idx_test = id_to_submit.user_id.values\n",
    "mat_test = mat[idx_test]\n",
    "\n",
    "cols_countsum_tr = np.asarray(mat_train.astype(bool).sum(axis=0)).flatten()\n",
    "cols_countsum_test = np.asarray(mat_test.astype(bool).sum(axis=0)).flatten()\n",
    "mask = (cols_countsum_tr > 1) * (cols_countsum_test > 0)\n",
    "\n",
    "mat_train = mat_train[:, mask]\n",
    "mat_test = mat_test[:, mask]\n",
    "print(mat_train.shape, mat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a26fd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>morning</th>\n",
       "      <th>night</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>...</th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "      <th>os</th>\n",
       "      <th>region_name_count</th>\n",
       "      <th>city_name_count</th>\n",
       "      <th>req_max</th>\n",
       "      <th>req_sum</th>\n",
       "      <th>id_rows</th>\n",
       "      <th>days</th>\n",
       "      <th>dates_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.554404</td>\n",
       "      <td>0.321244</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.134715</td>\n",
       "      <td>0.108808</td>\n",
       "      <td>0.036269</td>\n",
       "      <td>0.440415</td>\n",
       "      <td>...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Galaxy J1 2016 LTE Dual</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>131</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.346705</td>\n",
       "      <td>0.295129</td>\n",
       "      <td>0.322827</td>\n",
       "      <td>0.035339</td>\n",
       "      <td>0.127985</td>\n",
       "      <td>0.209169</td>\n",
       "      <td>0.102197</td>\n",
       "      <td>0.098376</td>\n",
       "      <td>0.122254</td>\n",
       "      <td>0.150907</td>\n",
       "      <td>...</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>Mi 9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1047</td>\n",
       "      <td>700</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.316302</td>\n",
       "      <td>0.187348</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.128954</td>\n",
       "      <td>0.148418</td>\n",
       "      <td>0.150852</td>\n",
       "      <td>0.104623</td>\n",
       "      <td>0.128954</td>\n",
       "      <td>...</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>Honor 9 Lite</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>411</td>\n",
       "      <td>356</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.178182</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.185455</td>\n",
       "      <td>0.065455</td>\n",
       "      <td>0.116364</td>\n",
       "      <td>0.123636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>Huawei Device Company Limited</td>\n",
       "      <td>P Smart 2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>275</td>\n",
       "      <td>188</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348777</td>\n",
       "      <td>0.265122</td>\n",
       "      <td>0.371943</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0.212355</td>\n",
       "      <td>0.164736</td>\n",
       "      <td>0.185328</td>\n",
       "      <td>0.141570</td>\n",
       "      <td>0.118404</td>\n",
       "      <td>0.072072</td>\n",
       "      <td>...</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>Nova 3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>777</td>\n",
       "      <td>591</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              day   evening   morning     night    Friday    Monday  Saturday  \\\n",
       "user_id                                                                         \n",
       "0        0.554404  0.321244  0.119171  0.005181  0.056995  0.020725  0.134715   \n",
       "1        0.346705  0.295129  0.322827  0.035339  0.127985  0.209169  0.102197   \n",
       "2        0.481752  0.316302  0.187348  0.014599  0.153285  0.128954  0.148418   \n",
       "3        0.352727  0.454545  0.178182  0.014545  0.240000  0.185455  0.065455   \n",
       "4        0.348777  0.265122  0.371943  0.014157  0.212355  0.164736  0.185328   \n",
       "\n",
       "           Sunday  Thursday   Tuesday  ...                        company  \\\n",
       "user_id                                ...                                  \n",
       "0        0.108808  0.036269  0.440415  ...                        Samsung   \n",
       "1        0.098376  0.122254  0.150907  ...                         Xiaomi   \n",
       "2        0.150852  0.104623  0.128954  ...                         Huawei   \n",
       "3        0.116364  0.123636  0.090909  ...  Huawei Device Company Limited   \n",
       "4        0.141570  0.118404  0.072072  ...                         Huawei   \n",
       "\n",
       "                           model os region_name_count city_name_count req_max  \\\n",
       "user_id                                                                         \n",
       "0        Galaxy J1 2016 LTE Dual  1                 1               1       5   \n",
       "1                           Mi 9  1                 3               6       6   \n",
       "2                   Honor 9 Lite  1                 1               1       4   \n",
       "3                   P Smart 2021  1                 1               1       5   \n",
       "4                         Nova 3  1                 5               9       5   \n",
       "\n",
       "         req_sum  id_rows  days  dates_range  \n",
       "user_id                                       \n",
       "0            193      131    17           18  \n",
       "1           1047      700    19           20  \n",
       "2            411      356    50           57  \n",
       "3            275      188    15           16  \n",
       "4            777      591    20           42  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_df = pd.read_csv('../utils/feat_gen_df3.csv', index_col='user_id')\n",
    "feat_df['os'] = feat_df['os'].map({'iOS': 0, 'Android': 1})\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "959d7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feat = feat_df.drop(['region_name', 'city_name', 'company', 'model'], axis=1).values\n",
    "cont_feat_train = cont_feat[idx_tr]\n",
    "cont_feat_test = cont_feat[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5f5274",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = feat_df[['region_name', 'city_name', 'company', 'model']]\n",
    "cat_feat = np.stack([cat_df[col].astype('category').cat.codes.values for col in cat_df]).T\n",
    "cat_feat_train = cat_feat[idx_tr]\n",
    "cat_feat_test = cat_feat[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "805eaa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269903, 173452) (144724, 173452)\n"
     ]
    }
   ],
   "source": [
    "mat_pod = load_npz('../utils/mat_pod.npz')\n",
    "mat_pod_train = mat_pod[idx_tr]\n",
    "mat_pod_test = mat_pod[idx_test]\n",
    "\n",
    "mat_pod_cols_countsum_tr = np.asarray(mat_pod_train.astype(bool).sum(axis=0)).flatten()\n",
    "mat_pod_cols_countsum_test = np.asarray(mat_pod_test.astype(bool).sum(axis=0)).flatten()\n",
    "mat_pod_mask = (mat_pod_cols_countsum_tr > 1) * (mat_pod_cols_countsum_test > 0)\n",
    "\n",
    "mat_pod_train = mat_pod_train[:, mat_pod_mask]\n",
    "mat_pod_test = mat_pod_test[:, mat_pod_mask]\n",
    "print(mat_pod_train.shape, mat_pod_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b9b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x1_vals, x2_vals, x3_vals, x4_vals, y_vals, batch_size, split_idx, shuffle_idx=False):\n",
    "        self.x1_vals = x1_vals\n",
    "        self.x2_vals = x2_vals\n",
    "        self.x3_vals = x3_vals\n",
    "        self.x4_vals = x4_vals\n",
    "        self.y_vals = y_vals\n",
    "        self.inds = split_idx\n",
    "        self.shuffle_idx = shuffle_idx\n",
    "        if shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        from_ind = self.batch_size * item\n",
    "        to_ind = self.batch_size * (item + 1)\n",
    "        batch_x1 = self.x1_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        batch_x2 = self.x2_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x3 = self.x3_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x4 = self.x4_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        batch_y = self.y_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        return ([batch_x1, batch_x2, batch_x3, batch_x4], tf.one_hot(batch_y, depth=6))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.inds) / float(self.batch_size)))\n",
    "    \n",
    "    \n",
    "class DataGenerator_test(Sequence):\n",
    "    def __init__(self, x1_vals, x2_vals, x3_vals, x4_vals, batch_size, split_idx, shuffle_idx=False):\n",
    "        self.x1_vals = x1_vals\n",
    "        self.x2_vals = x2_vals\n",
    "        self.x3_vals = x3_vals\n",
    "        self.x4_vals = x4_vals\n",
    "        self.inds = split_idx\n",
    "        self.shuffle_idx = shuffle_idx\n",
    "        if shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        from_ind = self.batch_size * item\n",
    "        to_ind = self.batch_size * (item + 1)\n",
    "        batch_x1 = self.x1_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        batch_x2 = self.x2_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x3 = self.x3_vals[np.sort(self.inds[from_ind:to_ind])]\n",
    "        batch_x4 = self.x4_vals[np.sort(self.inds[from_ind:to_ind])].todense()\n",
    "        return ([batch_x1, batch_x2, batch_x3, batch_x4],)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle_idx:\n",
    "            shuffle(self.inds)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.inds) / float(self.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f8c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedLinearUnit(L.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.linear = L.Dense(units)\n",
    "        self.sigmoid = L.Dense(units, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.linear(inputs) * self.sigmoid(inputs)\n",
    "    \n",
    "    \n",
    "class GatedResidualNetwork(L.Layer):\n",
    "    def __init__(self, units, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.relu_dense = L.Dense(units, activation=\"relu\")\n",
    "        self.linear_dense = L.Dense(units)\n",
    "        self.dropout = L.Dropout(dropout_rate)\n",
    "        self.gated_linear_unit = GatedLinearUnit(units)\n",
    "        self.layer_norm = L.LayerNormalization()\n",
    "        self.project = L.Dense(units)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.relu_dense(inputs)\n",
    "        x = self.linear_dense(x)\n",
    "        x = self.dropout(x)\n",
    "        if inputs.shape[-1] != self.units:\n",
    "            inputs = self.project(inputs)\n",
    "        x = inputs + self.gated_linear_unit(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class VariableSelection(L.Layer):\n",
    "    def __init__(self, num_features, units, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.grns = list()\n",
    "        # Create a GRN for each feature independently\n",
    "        for idx in range(num_features):\n",
    "            grn = GatedResidualNetwork(units, dropout_rate)\n",
    "            self.grns.append(grn)\n",
    "        # Create a GRN for the concatenation of all the features\n",
    "        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n",
    "        self.softmax = L.Dense(units=num_features, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        v = L.concatenate(inputs)\n",
    "        v = self.grn_concat(v)\n",
    "        v = tf.expand_dims(self.softmax(v), axis=-1)\n",
    "\n",
    "        x = []\n",
    "        for idx, input_ in enumerate(inputs):\n",
    "            x.append(self.grns[idx](input_))\n",
    "        x = tf.stack(x, axis=1)\n",
    "\n",
    "        outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class VariableSelectionFlow(L.Layer):\n",
    "    def __init__(self, num_features, units, dropout_rate, dense_units=None):\n",
    "        super().__init__()\n",
    "        self.variableselection = VariableSelection(num_features, units, dropout_rate)\n",
    "        self.split = L.Lambda(lambda t: tf.split(t, num_features, axis=-1))\n",
    "        self.dense = dense_units\n",
    "        if dense_units:\n",
    "            self.dense_list = [L.Dense(dense_units, \\\n",
    "                                       activation='linear') \\\n",
    "                               for _ in tf.range(num_features)\n",
    "                              ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        split_input = self.split(inputs)\n",
    "        if self.dense:\n",
    "            #@tf.function\n",
    "            #def calc_cycle(layers_list, values_list):\n",
    "            #    return [layers_list[i](values_list[i]) for i in range(len(layers_list))]\n",
    "            #l = calc_cycle(self.dense_list, split_input)\n",
    "            l = [self.dense_list[i](split_input[i]) for i in range(len(self.dense_list))]\n",
    "        else:\n",
    "            l = split_input\n",
    "        return self.variableselection(l)        \n",
    "    \n",
    "    \n",
    "def smish(x):\n",
    "    return x * K.tanh(K.log(1 + K.sigmoid(x)))\n",
    "\n",
    "\n",
    "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
    "\n",
    "    mlp_layers = []\n",
    "    for units in hidden_units:\n",
    "        mlp_layers.append(L.Dense(units, activation=activation))\n",
    "        mlp_layers.append(normalization_layer),\n",
    "        mlp_layers.append(L.Dropout(dropout_rate))\n",
    "\n",
    "    return tf.keras.Sequential(mlp_layers, name=name)\n",
    "\n",
    "\n",
    "class TransformerBlock(L.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.15, num_transformer_blocks=3):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.num_transformer_blocks = num_transformer_blocks\n",
    "        self.att = L.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)\n",
    "        self.ffn = create_mlp(\n",
    "            hidden_units=ff_dim,\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=tf.keras.activations.gelu,\n",
    "            normalization_layer=L.LayerNormalization(epsilon=1e-6),\n",
    "        )\n",
    "        self.layernorm1 = L.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = L.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        for block_idx in range(num_transformer_blocks):\n",
    "            attn_output = self.att(inputs, inputs)\n",
    "            out1 = self.layernorm1(inputs + attn_output)\n",
    "            ffn_output = self.ffn(out1)\n",
    "            inputs = self.layernorm2(out1 + ffn_output)\n",
    "        return inputs\n",
    "\n",
    "    \n",
    "class Wt_Add(L.Layer):\n",
    "    def __init__(self, units=1, input_dim=1):\n",
    "        super(Wt_Add, self).__init__()\n",
    "        w_init = tf.random_normal_initializer(mean=1.0)\n",
    "        self.w1 = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.w2 = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )        \n",
    "        \n",
    "    def call(self, input1, input2):\n",
    "        return tf.multiply(input1,self.w1) + tf.multiply(input2, self.w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e05b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "units_1 = 256\n",
    "units_2 = 64\n",
    "units_22 = 128\n",
    "dropout_1 = 0.1\n",
    "dropout_2 = 0.1\n",
    "dropout_22 = 0.1\n",
    "\n",
    "\n",
    "INIT_LR = 1e-5\n",
    "MAX_LR = 1e-3\n",
    "steps_per_epoch = 949\n",
    "\n",
    "\n",
    "dropout_rate = 0.10\n",
    "num_transformer_blocks = 3  # Number of transformer blocks.\n",
    "num_heads = 4  # Number of attention heads.\n",
    "embedding_dims = 32  # Embedding dimensions of the categorical features.\n",
    "vocab_len = [80, 950, 37, 599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b16742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fbf306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###__--__###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ed2695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3080 Laptop GPU, compute capability 8.6\n",
      "______fold 1______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2741s 2s/step - loss: 1.3049 - f1_score: 0.4222 - val_loss: 1.2330 - val_f1_score: 0.4466\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2198s 2s/step - loss: 1.1808 - f1_score: 0.4870 - val_loss: 1.1862 - val_f1_score: 0.4846\n",
      "566/566 [==============================] - 507s 789ms/step\n",
      "______fold 2______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2773s 2s/step - loss: 1.3100 - f1_score: 0.4209 - val_loss: 1.2519 - val_f1_score: 0.4246\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2190s 2s/step - loss: 1.1823 - f1_score: 0.4871 - val_loss: 1.1878 - val_f1_score: 0.4789\n",
      "566/566 [==============================] - 498s 766ms/step\n",
      "______fold 3______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2751s 2s/step - loss: 1.2951 - f1_score: 0.4286 - val_loss: 1.2661 - val_f1_score: 0.4457\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2203s 2s/step - loss: 1.1777 - f1_score: 0.4902 - val_loss: 1.1882 - val_f1_score: 0.4800\n",
      "566/566 [==============================] - 514s 795ms/step\n",
      "______fold 4______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2768s 2s/step - loss: 1.3067 - f1_score: 0.4204 - val_loss: 1.2355 - val_f1_score: 0.4492\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2222s 2s/step - loss: 1.1811 - f1_score: 0.4865 - val_loss: 1.1959 - val_f1_score: 0.4822\n",
      "566/566 [==============================] - 500s 769ms/step\n",
      "______fold 5______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2747s 2s/step - loss: 1.3039 - f1_score: 0.4224 - val_loss: 1.2404 - val_f1_score: 0.4511\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2293s 2s/step - loss: 1.1825 - f1_score: 0.4860 - val_loss: 1.1884 - val_f1_score: 0.4827\n",
      "566/566 [==============================] - 524s 803ms/step\n",
      "______fold 6______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2825s 2s/step - loss: 1.3054 - f1_score: 0.4227 - val_loss: 1.2416 - val_f1_score: 0.4593\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2265s 2s/step - loss: 1.1869 - f1_score: 0.4837 - val_loss: 1.1845 - val_f1_score: 0.4871\n",
      "566/566 [==============================] - 513s 792ms/step\n",
      "______fold 7______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2790s 2s/step - loss: 1.3050 - f1_score: 0.4213 - val_loss: 1.2381 - val_f1_score: 0.4473\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2266s 2s/step - loss: 1.1794 - f1_score: 0.4884 - val_loss: 1.1921 - val_f1_score: 0.4768\n",
      "566/566 [==============================] - 521s 799ms/step\n",
      "______fold 8______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2790s 2s/step - loss: 1.3117 - f1_score: 0.4184 - val_loss: 1.2492 - val_f1_score: 0.4333\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2204s 2s/step - loss: 1.1812 - f1_score: 0.4876 - val_loss: 1.1972 - val_f1_score: 0.4777\n",
      "566/566 [==============================] - 502s 771ms/step\n",
      "______fold 9______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2773s 2s/step - loss: 1.3037 - f1_score: 0.4229 - val_loss: 1.2329 - val_f1_score: 0.4510\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2260s 2s/step - loss: 1.1759 - f1_score: 0.4905 - val_loss: 1.1893 - val_f1_score: 0.4839\n",
      "566/566 [==============================] - 522s 800ms/step\n",
      "______fold 10______\n",
      "Epoch 1/2\n",
      "949/949 [==============================] - 2867s 2s/step - loss: 1.3011 - f1_score: 0.4242 - val_loss: 1.2321 - val_f1_score: 0.4560\n",
      "Epoch 2/2\n",
      "949/949 [==============================] - 2232s 2s/step - loss: 1.1782 - f1_score: 0.4882 - val_loss: 1.1891 - val_f1_score: 0.4817\n",
      "566/566 [==============================] - 499s 767ms/step\n",
      "CPU times: total: 8h 17min 45s\n",
      "Wall time: 15h 29min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "policy_m16 = mixed_precision.Policy('mixed_float16')\n",
    "policy_32 = mixed_precision.Policy('float32')\n",
    "\n",
    "test_gen = DataGenerator_test(mat_test,\\\n",
    "                              cont_feat_test,\\\n",
    "                              cat_feat_test,\\\n",
    "                              mat_pod_test,\\\n",
    "                              batch_size,\n",
    "                              np.arange(mat_test.shape[0])\n",
    "                           )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=723)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(np.arange(mat_train.shape[0]), y_train)):\n",
    "    print(f'______fold {n+1}______')\n",
    "    train_idx = np.sort(train_idx)\n",
    "    val_idx = np.sort(val_idx) \n",
    "    train_gen = DataGenerator(mat_train,\\\n",
    "                              cont_feat_train,\\\n",
    "                              cat_feat_train,\\\n",
    "                              mat_pod_train,\\\n",
    "                              y_train,\\\n",
    "                              batch_size,\\\n",
    "                              train_idx,\\\n",
    "                              shuffle_idx=True\n",
    "                             )\n",
    "    val_gen = DataGenerator(mat_train,\\\n",
    "                            cont_feat_train,\\\n",
    "                            cat_feat_train,\\\n",
    "                            mat_pod_train,\\\n",
    "                            y_train,\\\n",
    "                            batch_size,\n",
    "                            val_idx\n",
    "                           )\n",
    "    \n",
    "    mixed_precision.set_global_policy(policy_m16)\n",
    "\n",
    "    inputs_1 = tf.keras.Input(shape=(88072,))\n",
    "    r1_1 = L.Reshape((1,88072,1))(inputs_1)\n",
    "    cnn_1 = L.Conv2D(16, (1,41), strides=2, activation=smish)(r1_1)\n",
    "    \n",
    "    mixed_precision.set_global_policy(policy_32)\n",
    "\n",
    "    d_1 = L.Dense(1, activation=smish)(cnn_1)\n",
    "    r2_1 = L.Reshape((44016,))(d_1)\n",
    "    features_1 = VariableSelectionFlow(168, units_1, dropout_1)(r2_1)\n",
    "    \n",
    "   \n",
    "    inputs_2 = tf.keras.Input(shape=(20,), dtype=tf.int32)\n",
    "    features_2 = VariableSelectionFlow(20, units_2, dropout_2, dense_units=1)(inputs_2)\n",
    "\n",
    "    \n",
    "    inputs_3 = tf.keras.Input(shape=(4,), dtype=tf.int16)\n",
    "    n_0 = L.Lambda(lambda t: tf.split(t, 4, axis=-1))(inputs_3)\n",
    "    emb = [L.Embedding(input_dim=vocab_len[n], output_dim=embedding_dims)(l) for n, l in enumerate(n_0)]\n",
    "    cat_emb = tf.concat(emb, axis=1)    \n",
    "    transf_cat = TransformerBlock(embed_dim=embedding_dims, \\\n",
    "                                 num_heads=num_heads, \\\n",
    "                                 ff_dim=[embedding_dims], \\\n",
    "                                 dropout_rate=dropout_rate, \\\n",
    "                                 num_transformer_blocks=num_transformer_blocks\n",
    "                                )(cat_emb)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    cat_features = L.Flatten()(transf_cat)\n",
    "\n",
    "    mixed_precision.set_global_policy(policy_m16)    \n",
    "    \n",
    "    inputs_4 = tf.keras.Input(shape=(173452,))\n",
    "    r1_4 = L.Reshape((1,173452,1))(inputs_4)\n",
    "    cnn_4 = L.Conv2D(4, (1,53), strides=2, activation=smish)(r1_4)\n",
    "    \n",
    "    mixed_precision.set_global_policy(policy_32)\n",
    "    \n",
    "    d_4 = L.Dense(1, activation=smish)(cnn_4)    \n",
    "    r2_4 = L.Reshape((86700,))(d_4)\n",
    "    features_4 = VariableSelectionFlow(255, units_1, dropout_1)(r2_4)   \n",
    "\n",
    "    \n",
    "    add_1_4 = Wt_Add(units=units_1)(features_1, features_4)\n",
    "    \n",
    "    \n",
    "    concat1 = L.Concatenate()([features_2, cat_features, add_1_4])\n",
    "    \n",
    "    features_22 = VariableSelectionFlow(concat1.shape[-1], units_22, dropout_22)(concat1)\n",
    "    \n",
    "    dense_out = L.Dense(6)(features_22)\n",
    "    outputs = L.Activation(\"softmax\", dtype='float32')(dense_out)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2, inputs_3, inputs_4], outputs=outputs)\n",
    "                \n",
    "    clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "        maximal_learning_rate=MAX_LR,\n",
    "        scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "        step_size=1 * steps_per_epoch\n",
    "        )\n",
    "    \n",
    "    opt = O.Adam(learning_rate=clr, epsilon=1e-09)\n",
    "    loss = categorical_crossentropy\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                    loss=loss,\n",
    "                    metrics=[F1Score(num_classes=6, average='weighted')]\n",
    "                 )\n",
    "    \n",
    "    model.fit(train_gen,\n",
    "                epochs=2,\n",
    "                validation_data=val_gen\n",
    "            )\n",
    "\n",
    "    y_test_df = pd.DataFrame(idx_test).rename({0: 'user_id'}, axis=1)\n",
    "    y_test_df[[str(i) for i in (range(1,7))]] = model.predict(test_gen)\n",
    "    y_test_df = y_test_df.set_index('user_id', drop=True)\n",
    "    y_test_df.to_csv(f'v128_723/fold_{n+1}/y_test.csv')\n",
    "    \n",
    "    del model, clr, opt, loss\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cedecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07a4b73d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 88072)]      0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 173452)]     0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 88072, 1)     0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 173452, 1)    0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              [(None, 1),          0           ['input_3[0][0]']                \n",
      "                                 (None, 1),                                                       \n",
      "                                 (None, 1),                                                       \n",
      "                                 (None, 1)]                                                       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 44016, 16)    672         ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 86700, 4)     216         ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 32)        2560        ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 32)        30400       ['lambda_2[0][1]']               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 1, 32)        1184        ['lambda_2[0][2]']               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 1, 32)        19168       ['lambda_2[0][3]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 44016, 1)     17          ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_974 (Dense)              (None, 86700, 1)     5           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 4, 32)        0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]',            \n",
      "                                                                  'embedding_2[0][0]',            \n",
      "                                                                  'embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 44016)        0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 86700)        0           ['dense_974[0][0]']              \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " transformer_block (Transformer  (None, 4, 32)       18048       ['tf.concat[0][0]']              \n",
      " Block)                                                                                           \n",
      "                                                                                                  \n",
      " variable_selection_flow (Varia  (None, 256)         78645160    ['reshape_1[0][0]']              \n",
      " bleSelectionFlow)                                                                                \n",
      "                                                                                                  \n",
      " variable_selection_flow_2 (Var  (None, 256)         139636735   ['reshape_3[0][0]']              \n",
      " iableSelectionFlow)                                                                              \n",
      "                                                                                                  \n",
      " variable_selection_flow_1 (Var  (None, 64)          273916      ['input_2[0][0]']                \n",
      " iableSelectionFlow)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['transformer_block[0][0]']      \n",
      "                                                                                                  \n",
      " wt__add (Wt_Add)               (None, 256)          512         ['variable_selection_flow[0][0]',\n",
      "                                                                  'variable_selection_flow_2[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 448)          0           ['variable_selection_flow_1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'wt__add[0][0]']                \n",
      "                                                                                                  \n",
      " variable_selection_flow_3 (Var  (None, 128)         22758720    ['concatenate[0][0]']            \n",
      " iableSelectionFlow)                                                                              \n",
      "                                                                                                  \n",
      " dense_4502 (Dense)             (None, 6)            774         ['variable_selection_flow_3[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 6)            0           ['dense_4502[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 241,388,087\n",
      "Trainable params: 241,388,087\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9241c910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_env_v1] *",
   "language": "python",
   "name": "conda-env-ml_env_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
